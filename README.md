# ğŸ’£ Text2VR: Multi-modal Generative Model for Immersive Virtual Reality  (Working Repositotry)
> **Capstone Design Project** | Graduation 2025  
> **Theme**: Conditional Diffusion / Multi-modal Generation for VR World Synthesis

---

ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£  
## ğŸ”¥ CRAZY Capstone Design for Graduation ğŸ”¥  
### ğŸ“ Team ê°€ë¼ì‚¬ë‹ˆ (GARASANI)

| ğŸ‘¤ Name | ğŸŒ GitHub |
|:--------:|:--------:|
| LEE Changmin (ì´ì°½ë¯¼) | <img src="https://img.shields.io/badge/GitHub-LeeChangmin0310-181717?style=flat&logo=GitHub&logoColor=white"> |
| MYEONG Suyeon (ëª…ìˆ˜ì—°) | <img src="https://img.shields.io/badge/GitHub-suyeonmyeong-181717?style=flat&logo=GitHub&logoColor=white"> |
| AHN Munsik (ì•ˆë¬¸ì‹) | <img src="https://img.shields.io/badge/GitHub-dalsik-181717?style=flat&logo=GitHub&logoColor=white"> |
| JIN Yeoungin (ì§„ì˜ì¸) | <img src="https://img.shields.io/badge/GitHub-0in11-181717?style=flat&logo=GitHub&logoColor=white"> |
<br/>

ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£ğŸ§¨ğŸ’£  

---

ğŸ¯ **Goal**  
> To build a generative system that transforms multi-modal inputs (e.g., text, image, audio) into immersive virtual reality content using diffusion-based or transformer-based architectures.

ğŸ’¡ **Keywords**: `VR`, `Diffusion Model`, `Multimodal`, `Text2Scene`, `Generative AI`, `3D Synthesis`

---

âœ¨ *"From language to landscape, we bring imagination to immersive reality."*
