# 💣 Text2VR: Multi-modal Generative Model for Immersive Virtual Reality  (Working Repositotry)
> **Capstone Design Project** | Graduation 2025  
> **Theme**: Conditional Diffusion / Multi-modal Generation for VR World Synthesis

---

🧨💣🧨💣🧨💣🧨💣🧨💣🧨💣🧨💣🧨💣  
## 🔥 CRAZY Capstone Design for Graduation 🔥  
### 🎓 Team 가라사니 (GARASANI)

| 👤 Name | 🌐 GitHub |
|:--------:|:--------:|
| LEE Changmin (이창민) | <img src="https://img.shields.io/badge/GitHub-LeeChangmin0310-181717?style=flat&logo=GitHub&logoColor=white"> |
| MYEONG Suyeon (명수연) | <img src="https://img.shields.io/badge/GitHub-suyeonmyeong-181717?style=flat&logo=GitHub&logoColor=white"> |
| AHN Munsik (안문식) | <img src="https://img.shields.io/badge/GitHub-dalsik-181717?style=flat&logo=GitHub&logoColor=white"> |
| JIN Yeoungin (진영인) | <img src="https://img.shields.io/badge/GitHub-0in11-181717?style=flat&logo=GitHub&logoColor=white"> |
<br/>

🧨💣🧨💣🧨💣🧨💣🧨💣🧨💣🧨💣🧨💣  

---

🎯 **Goal**  
> To build a generative system that transforms multi-modal inputs (e.g., text, image, audio) into immersive virtual reality content using diffusion-based or transformer-based architectures.

💡 **Keywords**: `VR`, `Diffusion Model`, `Multimodal`, `Text2Scene`, `Generative AI`, `3D Synthesis`

---

✨ *"From language to landscape, we bring imagination to immersive reality."*
